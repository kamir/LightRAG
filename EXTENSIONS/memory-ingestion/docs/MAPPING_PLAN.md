# Memory API to LightRAG Mapping Plan

**Version:** 1.0
**Date:** 2025-12-18
**Status:** DRAFT - Pending Review

---

## Executive Summary

This document defines the comprehensive data mapping strategy between the Memory API (source system) and LightRAG (target knowledge graph system). The plan ensures **complete traceability**, **rich metadata preservation**, and **effective knowledge graph utilization** for all ingested memories.

---

## 1. Current State Analysis

### 1.1 Memory API Data Model

```json
{
  "id": "string",                    // Unique memory identifier
  "type": "memory",                  // Memory type classification
  "audio": boolean,                  // Has audio content
  "image": boolean,                  // Has image content
  "gcs_uri": "string",              // Audio file location (GCS)
  "gcs_uri_img": "string",          // Image file location (GCS)
  "transcript": "string",           // Primary text content
  "description": "string",          // AI-generated summary
  "location_lat": float,            // Geolocation latitude
  "location_lon": float,            // Geolocation longitude
  "created_at": "ISO-8601",         // Creation timestamp
  "updated_at": "ISO-8601",         // Last update timestamp
  "context_id": "string",           // User/context identifier
  "collection_name": "string",      // Collection grouping
  "tags": ["string"],               // User-defined tags
  "transcript_status": "string"     // Processing status
}
```

### 1.2 LightRAG Data Model (Discovered)

#### Document Level
```python
{
  "doc_id": "doc-{md5_hash}",       // Auto-generated ID
  "content": "string",              // Full document text
  "file_path": "string"             // Source citation (CRITICAL for traceability)
}
```

#### Chunk Level
```python
{
  "chunk_id": "chunk-{md5_hash}",
  "content": "string",
  "full_doc_id": "string",          // Links back to document
  "chunk_order_index": int,
  "tokens": int,
  "file_path": "string"             // Preserved for citation
}
```

#### Entity (Knowledge Graph Node)
```python
{
  "entity_id": "string",            // Entity name
  "entity_type": "string",          // Classification (PERSON, PLACE, etc.)
  "description": "string",          // Entity description
  "source_id": "string",            // <SEP>-delimited chunk IDs (CRITICAL for traceability)
  "file_path": "string",            // <SEP>-delimited source paths
  "created_at": int                 // Unix timestamp
}
```

#### Relationship (Knowledge Graph Edge)
```python
{
  "src_id": "string",               // Source entity
  "tgt_id": "string",               // Target entity
  "weight": float,                  // Relationship strength
  "description": "string",          // Relationship description
  "keywords": "string",             // Relationship type/keywords
  "source_id": "string",            // <SEP>-delimited chunk IDs
  "file_path": "string",            // <SEP>-delimited source paths
  "created_at": int
}
```

#### Vector Storage Metadata (Indexed)
- `entity_name`
- `source_id`
- `content`
- `file_path`

### 1.3 Current Mapping Issues

❌ **Ad-hoc `file_path` generation**: Currently using `api://memory-connector/{memory_id}`
❌ **Metadata not structured**: Inconsistent metadata fields across strategies
❌ **No reverse lookup**: Cannot efficiently query "which memories mention person X?"
❌ **Lost context**: Audio/image references, location data not leveraged
❌ **No collection tracking**: Cannot filter by collection or context_id in queries
❌ **Temporal data underutilized**: Created_at stored as string, not queryable by date ranges

---

## 2. Proposed Mapping Strategy

### 2.1 Document Mapping

#### Principle: One Memory = One Document

**Input:** Memory API item
**Output:** LightRAG document

#### Field Mapping

| Memory API Field | LightRAG Field | Mapping Logic |
|-----------------|----------------|---------------|
| `id` | `file_path` | **`memory://{context_id}/{id}`** (URI scheme for traceability) |
| `transcript` | `content` (primary) | Direct mapping - main text content |
| `description` | `content` (enriched) | Prepend as context: `"{description}\n\n{transcript}"` |
| - | `doc_id` | Auto-generated by LightRAG: `doc-{md5(content)}` |

**Why `file_path` = `memory://{context_id}/{id}`?**
- ✅ Unique identifier across all memories
- ✅ Preserves context_id for multi-tenant filtering
- ✅ Enables reverse lookup: "Show me source of this entity"
- ✅ Compatible with LightRAG's citation system
- ✅ Can be parsed back to original Memory API ID

**Example:**
```
file_path: "memory://107677460544181387647___mft/fJQAOybZ4366sQHKd40O"
content: "[Memory from 2024-01-19 07:28:08 UTC]\nJa, hallo, das ist eine Notiz..."
```

---

### 2.2 Metadata Mapping (Standard Strategy)

Store as **LightRAG document metadata** (passed in `InsertTextRequest`).

#### Core Metadata (Always Included)

```python
metadata = {
    # === SOURCE TRACEABILITY ===
    "memory_id": memory.ID,                    # Original Memory API ID
    "context_id": memory.ContextID,            # User/context identifier
    "file_path": f"memory://{memory.ContextID}/{memory.ID}",  # Canonical URI

    # === TEMPORAL METADATA ===
    "created_at": memory.CreatedAt,            # ISO-8601 timestamp (preserve as-is)
    "created_year": "2024",                    # Extracted year (queryable)
    "created_month": "01",                     # Extracted month (queryable)
    "created_date": "2024-01-19",              # Date only (queryable)
    "created_timestamp": 1705651688,           # Unix timestamp (sortable)

    # === CLASSIFICATION ===
    "memory_type": memory.Type,                # "memory", "note", etc.
    "collection_name": memory.CollectionName,  # Grouping/categorization
    "transcript_status": memory.TranscriptStatus,  # Processing state

    # === MEDIA FLAGS ===
    "has_audio": "true" / "false",             # Boolean as string (indexed)
    "has_image": "true" / "false",             # Boolean as string (indexed)

    # === TRANSFORMATION INFO ===
    "transformation_strategy": "standard",     # Which strategy was used
    "ingestion_timestamp": "<ISO-8601>",       # When ingested into LightRAG
    "connector_id": "connector-3",             # Which connector ingested this
}
```

#### Optional Metadata (Conditional)

```python
# Only include if data exists

# Location (if has_location())
if memory.HasLocation():
    metadata["location_lat"] = "48.1234"
    metadata["location_lon"] = "11.5678"
    metadata["location_geohash"] = "u0qj"      # For spatial queries (compute from lat/lon)

# Media references (if available)
if memory.GcsUri:
    metadata["audio_uri"] = memory.GcsUri
    metadata["audio_filename"] = extract_filename(memory.GcsUri)  # e.g., "107677...memory.mp3"

if memory.GcsUriImg:
    metadata["image_uri"] = memory.GcsUriImg
    metadata["image_filename"] = extract_filename(memory.GcsUriImg)

# Tags (if available)
if len(memory.Tags) > 0:
    metadata["tags"] = ",".join(memory.Tags)   # Comma-separated for searchability
    metadata["tag_count"] = str(len(memory.Tags))

# Updated timestamp (if different from created)
if memory.UpdatedAt and memory.UpdatedAt != memory.CreatedAt:
    metadata["updated_at"] = memory.UpdatedAt
```

---

### 2.3 Content Transformation Strategy

#### Standard Strategy (Recommended for Most Use Cases)

**Goal:** Clean, focused content for entity extraction

```python
def transform_standard(memory: Memory, config: TransformConfig) -> (str, dict):
    """
    Standard transformation: Clear, concise content with essential metadata.
    Optimized for entity extraction and knowledge graph building.
    """

    # Build content
    content_parts = []

    # 1. Temporal context (helps with entity extraction)
    created_time = parse_iso8601(memory.CreatedAt)
    content_parts.append(f"[Memory from {created_time.strftime('%Y-%m-%d %H:%M:%S %Z')}]")

    # 2. Primary content
    content_parts.append(memory.Transcript)

    # 3. Media context (if relevant)
    if memory.HasAudio():
        content_parts.append("[Audio recording available]")
    if memory.HasImage():
        content_parts.append("[Image attachment available]")

    # 4. Location context (if available and enrichment enabled)
    if memory.HasLocation() and config.EnrichLocation:
        content_parts.append(
            f"[Location: {memory.LocationLat:.4f}, {memory.LocationLon:.4f}]"
        )

    content = "\n".join(content_parts)

    # Build metadata (see Section 2.2)
    metadata = build_core_metadata(memory, config)

    return content, metadata
```

**Example Output:**
```
[Memory from 2024-01-19 07:28:08 UTC]
Ja, hallo, das ist eine Notiz. Wir besprechen gerade die User journey für das ja für das tun ohne Namen.
[Audio recording available]
```

#### Rich Strategy (For Enhanced Context)

**Goal:** Maximum context for complex scenarios

```python
def transform_rich(memory: Memory, config: TransformConfig) -> (str, dict):
    """
    Rich transformation: Comprehensive content with full context.
    Use when: memories contain complex multi-modal data, or temporal/spatial context is critical.
    """

    content_parts = []

    # 1. Header with metadata
    created_time = parse_iso8601(memory.CreatedAt)
    content_parts.append("=" * 60)
    content_parts.append(f"MEMORY: {memory.ID}")
    content_parts.append(f"Date: {created_time.strftime('%Y-%m-%d %H:%M:%S %Z')}")
    content_parts.append(f"Type: {memory.Type}")
    if memory.CollectionName:
        content_parts.append(f"Collection: {memory.CollectionName}")
    content_parts.append("=" * 60)
    content_parts.append("")

    # 2. Description (if available)
    if memory.Description and memory.Description != memory.Transcript:
        content_parts.append(f"Summary: {memory.Description}")
        content_parts.append("")

    # 3. Primary content
    content_parts.append("Content:")
    content_parts.append(memory.Transcript)
    content_parts.append("")

    # 4. Media references
    media_info = []
    if memory.HasAudio():
        media_info.append(f"Audio: {memory.GcsUri}")
    if memory.HasImage():
        media_info.append(f"Image: {memory.GcsUriImg}")
    if media_info:
        content_parts.append("Attachments:")
        content_parts.extend(media_info)
        content_parts.append("")

    # 5. Location (if available)
    if memory.HasLocation():
        if config.EnrichLocation:
            # TODO: Reverse geocode to get place name
            location_name = reverse_geocode(memory.LocationLat, memory.LocationLon)
            content_parts.append(f"Location: {location_name} ({memory.LocationLat:.4f}, {memory.LocationLon:.4f})")
        else:
            content_parts.append(f"Location: {memory.LocationLat:.4f}, {memory.LocationLon:.4f}")
        content_parts.append("")

    # 6. Tags
    if len(memory.Tags) > 0:
        content_parts.append(f"Tags: {', '.join(memory.Tags)}")
        content_parts.append("")

    content = "\n".join(content_parts)

    # Build rich metadata (see Section 2.2)
    metadata = build_rich_metadata(memory, config)

    return content, metadata
```

**Example Output:**
```
============================================================
MEMORY: sgCZwsKY5TegqlfKA4VE
Date: 2024-01-19 07:28:08 UTC
Type: memory
Collection: default_collection
============================================================

Summary: Ja, hallo, das ist eine Notiz. Wir besprechen gerade die User journey für das ja für das tun ohne Namen.

Content:
Ja, hallo, das ist eine Notiz. Wir besprechen gerade die User journey für das ja für das tun ohne Namen.

Attachments:
Audio: gs://project_p4te/uploads/107677460544181387647___mft_2024-01-19 07:28:08_memory.mp3
Image: gs://project_p4te/uploads/image_107677460544181387647___mft_2024-01-19 07:28:08_memory.mp3.jpeg
```

---

### 2.4 Knowledge Graph Enrichment

After LightRAG processes the documents, entities and relationships will automatically inherit source metadata.

#### Entity Example

**Input Document:**
```
file_path: "memory://107677460544181387647___mft/fJQAOybZ4366sQHKd40O"
content: "Erik wird Thomas und Benny in das Tool einführen."
```

**Extracted Entity (Auto-generated by LightRAG):**
```python
{
  "entity_id": "Erik",
  "entity_type": "PERSON",
  "description": "Person who will introduce Thomas and Benny to the tool",
  "source_id": "chunk-abc123<SEP>chunk-def456",  # Chunks that mentioned Erik
  "file_path": "memory://107677460544181387647___mft/fJQAOybZ4366sQHKd40O<SEP>memory://...",
  "created_at": 1734545088
}
```

**Key Benefits:**
- ✅ `file_path` traces back to specific memories
- ✅ `source_id` identifies which text chunks mentioned this entity
- ✅ Can query: "Which memories mention Erik?" → Parse `file_path` → Extract memory IDs

#### Relationship Example

**Extracted Relationship:**
```python
{
  "src_id": "Erik",
  "tgt_id": "Tool",
  "weight": 1.0,
  "description": "will introduce others to",
  "keywords": "introduction,training",
  "source_id": "chunk-abc123",
  "file_path": "memory://107677460544181387647___mft/fJQAOybZ4366sQHKd40O",
  "created_at": 1734545088
}
```

---

### 2.5 Traceability Chain

#### Complete Audit Trail

```
User Query: "Who is Erik?"
    ↓
LightRAG Entity Search → Find entity "Erik"
    ↓
Entity has file_path: "memory://107677460544181387647___mft/fJQAOybZ4366sQHKd40O"
    ↓
Parse URI → Extract memory_id: "fJQAOybZ4366sQHKd40O"
    ↓
Connector can query Memory API: GET /memory/{context_id}/{memory_id}
    ↓
Return original memory with full metadata (audio, image, location, etc.)
```

#### Query Optimization

**Add custom query endpoint to connector:**

```go
// GET /api/v1/memories/by-entity?entity_name=Erik
func GetMemoriesByEntity(entityName string) ([]Memory, error) {
    // 1. Query LightRAG for entity
    entity := lightragClient.GetEntity(entityName)

    // 2. Parse file_path to extract memory IDs
    memoryIDs := parseMemoryURIs(entity.FilePath)

    // 3. Fetch full memories from Memory API
    memories := []Memory{}
    for _, id := range memoryIDs {
        memory := memoryClient.GetMemory(contextID, id)
        memories = append(memories, memory)
    }

    return memories, nil
}
```

---

## 3. Implementation Plan

### Phase 1: Update Transformer (Week 1)

**Files to Modify:**
- `pkg/transformer/strategies.go`
- `pkg/models/memory.go`

**Tasks:**
1. ✅ Implement `memory://` URI scheme for `file_path`
2. ✅ Add comprehensive metadata builder functions
3. ✅ Update `StandardStrategy.Transform()` with new content format
4. ✅ Update `RichStrategy.Transform()` with enhanced context
5. ✅ Add temporal metadata extraction (year, month, date, timestamp)
6. ✅ Add geohash generation for location data (optional)
7. ✅ Add unit tests for mapping logic

### Phase 2: Update Config Schema (Week 1)

**Files to Modify:**
- `configs/config.yaml`
- `pkg/config/config.go`
- `pkg/models/connector.go`

**Tasks:**
1. Add `metadata_mapping` section to connector config
2. Add `enable_location_enrichment` flag
3. Add `enable_media_context` flag
4. Add `timestamp_format` configuration
5. Update validation logic

**Example Config:**
```yaml
connectors:
  - id: "connector-1"
    # ... existing config ...

    metadata_mapping:
      include_temporal: true           # Extract year/month/date
      include_media_flags: true        # Add audio/image indicators
      include_location: true           # Include lat/lon if available
      include_tags: true               # Include user tags
      include_collection: true         # Include collection name

    transform:
      strategy: "standard"
      include_metadata: true
      enrich_location: false           # Reverse geocoding (future)
      media_context: "compact"         # "none", "compact", "detailed"
```

### Phase 3: Add Reverse Lookup API (Week 2)

**New Files:**
- `pkg/api/handlers/lookup.go`
- `pkg/api/routes.go` (update)

**Endpoints:**
1. `GET /api/v1/lookup/by-entity?name={entity_name}`
   - Query LightRAG for entity
   - Parse memory URIs from `file_path`
   - Return list of memory IDs

2. `GET /api/v1/lookup/by-memory?memory_id={id}`
   - Query LightRAG for all entities/relationships mentioning this memory
   - Return knowledge graph subgraph

3. `GET /api/v1/lookup/by-location?lat={lat}&lon={lon}&radius_km={km}`
   - Use geohash-based spatial query
   - Return memories within radius

### Phase 4: Update Documentation (Week 2)

**Files:**
- `QUICKSTART.md` (update)
- `README.md` (update)
- `docs/ARCHITECTURE.md` (new)
- `docs/METADATA_REFERENCE.md` (new)

**Content:**
- Explain memory:// URI scheme
- Document all metadata fields
- Provide query examples
- Show traceability workflows

### Phase 5: Testing & Validation (Week 2-3)

**Test Cases:**
1. **Mapping Accuracy**
   - Verify all Memory API fields are preserved
   - Validate URI format correctness
   - Check metadata completeness

2. **Traceability**
   - Query entity → Trace to memory → Verify match
   - Test reverse lookup endpoints
   - Validate citation generation

3. **Knowledge Graph Quality**
   - Verify entities are extracted correctly
   - Check relationship quality
   - Test multi-memory entity resolution

4. **Performance**
   - Measure ingestion time (target: <100ms per memory)
   - Monitor LightRAG query latency
   - Stress test with 10K+ memories

---

## 4. Metadata Field Reference

### 4.1 Required Metadata (Always Present)

| Field | Type | Example | Purpose |
|-------|------|---------|---------|
| `memory_id` | string | `"fJQAOybZ4366sQHKd40O"` | Original Memory API ID |
| `context_id` | string | `"107677460544181387647___mft"` | User/context identifier |
| `file_path` | string | `"memory://107677.../fJQA..."` | Canonical URI for traceability |
| `created_at` | ISO-8601 | `"2024-01-19T07:28:08Z"` | Original timestamp |
| `created_timestamp` | int | `1705651688` | Unix timestamp (sortable) |
| `transformation_strategy` | string | `"standard"` | Which strategy processed this |
| `ingestion_timestamp` | ISO-8601 | `"2025-12-18T18:30:00Z"` | When ingested |
| `connector_id` | string | `"connector-3"` | Which connector ingested |

### 4.2 Classification Metadata

| Field | Type | Example | Purpose |
|-------|------|---------|---------|
| `memory_type` | string | `"memory"` | Memory type classification |
| `collection_name` | string | `"default_collection"` | Grouping/categorization |
| `transcript_status` | string | `"processed"` | Processing state |

### 4.3 Temporal Metadata

| Field | Type | Example | Purpose |
|-------|------|---------|---------|
| `created_year` | string | `"2024"` | Queryable year |
| `created_month` | string | `"01"` | Queryable month (01-12) |
| `created_date` | string | `"2024-01-19"` | Queryable date |

### 4.4 Media Metadata

| Field | Type | Example | Purpose |
|-------|------|---------|---------|
| `has_audio` | string | `"true"` / `"false"` | Audio flag (indexed) |
| `has_image` | string | `"true"` / `"false"` | Image flag (indexed) |
| `audio_uri` | string | `"gs://project_p4te/..."` | Audio file location |
| `audio_filename` | string | `"107677...memory.mp3"` | Audio filename |
| `image_uri` | string | `"gs://project_p4te/..."` | Image file location |
| `image_filename` | string | `"image_107677...jpeg"` | Image filename |

### 4.5 Location Metadata

| Field | Type | Example | Purpose |
|-------|------|---------|---------|
| `location_lat` | string | `"48.1234"` | Latitude |
| `location_lon` | string | `"11.5678"` | Longitude |
| `location_geohash` | string | `"u0qj"` | Geohash for spatial queries |

### 4.6 Tag Metadata

| Field | Type | Example | Purpose |
|-------|------|---------|---------|
| `tags` | string | `"work,meeting,important"` | Comma-separated tags |
| `tag_count` | string | `"3"` | Number of tags |

---

## 5. Query Patterns

### 5.1 Temporal Queries

```python
# Find all memories from January 2024
query = {
    "metadata_filter": {
        "created_year": "2024",
        "created_month": "01"
    }
}
```

### 5.2 Media Queries

```python
# Find all memories with audio recordings
query = {
    "metadata_filter": {
        "has_audio": "true"
    }
}
```

### 5.3 Context Queries

```python
# Find all memories for a specific user
query = {
    "metadata_filter": {
        "context_id": "107677460544181387647___mft"
    }
}
```

### 5.4 Traceability Queries

```python
# Get source memories for an entity
entity = lightrag.get_entity("Erik")
memory_ids = parse_memory_uris(entity.file_path)
# memory_ids = ["fJQAOybZ4366sQHKd40O", "sgCZwsKY5TegqlfKA4VE", ...]
```

---

## 6. Success Criteria

### 6.1 Functional Requirements

- ✅ Every memory has unique, parseable `file_path` URI
- ✅ All Memory API fields are preserved in metadata
- ✅ Entities can be traced back to source memories
- ✅ Queries can filter by: date, context, media type, collection
- ✅ Citation system shows original memory source

### 6.2 Performance Requirements

- ✅ Ingestion: <100ms per memory
- ✅ Query latency: <500ms for entity lookup
- ✅ Reverse lookup: <1s for 100 related memories
- ✅ Support 10K+ memories without degradation

### 6.3 Data Quality Requirements

- ✅ 100% metadata preservation (no data loss)
- ✅ URI format validation (no malformed paths)
- ✅ Entity extraction quality >80% (manual review)
- ✅ Relationship accuracy >70% (manual review)

---

## 7. Migration Strategy

### 7.1 For Existing Data

If you've already ingested memories with the old `api://memory-connector/{id}` format:

**Option A: Re-ingest (Recommended)**
1. Delete existing documents from LightRAG
2. Re-sync with new mapping
3. Preserves data consistency

**Option B: Update in Place**
1. Query all documents with `file_path` starting with `api://`
2. Update `file_path` to new `memory://` format
3. Update metadata fields
4. Re-index

**Implementation:**
```bash
# Add to connector CLI
./bin/memory-connector migrate --from api-format --to memory-uri-format
```

---

## 8. Future Enhancements

### 8.1 Multi-modal Support (Phase 2)

- **Audio transcription**: Re-process audio files with Whisper for better quality
- **Image analysis**: Extract entities from images using vision models
- **Combined context**: Merge audio + image + text for richer entity extraction

### 8.2 Location Enrichment (Phase 2)

- **Reverse geocoding**: Convert lat/lon to place names
- **Spatial indexing**: Enable "memories near X" queries
- **Geofencing**: Group memories by location

### 8.3 Advanced Analytics (Phase 3)

- **Timeline view**: Visualize memories chronologically
- **Knowledge graph visualization**: Interactive graph explorer
- **Relationship strength**: Weight edges by co-occurrence frequency
- **Entity disambiguation**: Resolve "Erik" across multiple contexts

### 8.4 Real-time Sync (Phase 3)

- **Webhook integration**: Listen for new memories from Memory API
- **Incremental updates**: Update existing entities when memories change
- **Conflict resolution**: Handle overlapping entity definitions

---

## 9. Review Questions

### For Implementation Team

1. **URI Scheme**: Is `memory://{context_id}/{id}` sufficient, or should we include additional identifiers (e.g., timestamp, version)?

2. **Metadata Granularity**: Are the proposed metadata fields sufficient? Should we add:
   - `memory_version` (for updates)?
   - `source_system` (if multiple sources in future)?
   - `language` (detected from transcript)?

3. **Content Strategy**: Should we use Standard or Rich transformation by default? Should we support hybrid approaches?

4. **Location Enrichment**: Should reverse geocoding be:
   - On-demand (query time)?
   - Pre-computed (ingestion time)?
   - Disabled by default?

5. **Performance**: What's the acceptable ingestion rate?
   - 10 memories/second?
   - 100 memories/second?
   - Batch vs. streaming?

6. **Multi-tenancy**: Should we:
   - Create separate LightRAG workspaces per context_id?
   - Use single workspace with metadata filtering?
   - Support both modes?

7. **Data Privacy**: Should we:
   - Encrypt sensitive metadata fields?
   - Support GDPR right-to-deletion?
   - Add PII detection/masking?

### For Product/Business Team

1. **Traceability UI**: Should we build:
   - A web UI to explore entity → memory connections?
   - API-only for now?

2. **Query Modes**: Which LightRAG query modes to expose?
   - `local`: Entity-focused
   - `global`: Community-level insights
   - `hybrid`: Best of both

3. **Citation Format**: How to display memory citations in query results?
   - Show memory ID only?
   - Show timestamp + preview?
   - Link to original audio/image?

---

## 10. Appendices

### Appendix A: Code Examples

See `/examples/mapping_examples.go` for complete implementation examples.

### Appendix B: LightRAG API Reference

See `/docs/LIGHTRAG_API.md` for complete API documentation.

### Appendix C: Testing Data

See `/test/fixtures/memory_samples.json` for test memory data.

---

## Approval

**Prepared by:** Claude AI Assistant
**Review by:** [Your Name]
**Approved by:** [Stakeholder]
**Date:** _____________

---

**Next Steps:**
1. Review this plan
2. Provide feedback on review questions
3. Approve for implementation
4. Create implementation tickets
